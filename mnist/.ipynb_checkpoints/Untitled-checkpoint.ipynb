{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chunhui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb9c4849be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9c394f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"number of %d\" %train['label'][0])\n",
    "plt.imshow(train.drop(['label'], axis=1).iloc[0,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "idx = np.random.permutation(train.shape[0])\n",
    "mnist_train = train.iloc[idx[:40000],:]\n",
    "mnist_validation = train.iloc[idx[40000:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, batch_size, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    permutation  = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation,:]\n",
    "    Y = Y[permutation,:]\n",
    "    num_batch = int(X.shape[0]/batch_size)\n",
    "    batches=[]\n",
    "    for i in range(num_batch):\n",
    "        mini_X = X[i*batch_size:(i+1)*batch_size,:]\n",
    "        mini_Y = Y[i*batch_size:(i+1)*batch_size,:]\n",
    "        batches.append((mini_X, mini_Y))\n",
    "    if X.shape[0]%batch_size != 0:\n",
    "        mini_X = X[num_batch*batch_size:,:]\n",
    "        mini_Y = Y[num_batch*batch_size:,:]\n",
    "        batches.append((mini_X, mini_Y))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359.32600000000025\n"
     ]
    }
   ],
   "source": [
    "s = time.clock()\n",
    "b  = random_mini_batches(mnist_train_images, mnist_train_labels,128)\n",
    "e = time.clock()\n",
    "print(1000*(e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(data, labels, test, learning_rate_base=0.001, num_epoch=30000, batch_size=128, L2_lambd=0.0003 ,keep_prob=1.0):\n",
    "    tf.reset_default_graph()\n",
    "    #placeholder\n",
    "    X = tf.placeholder(tf.float32, shape=(None,28,28,1),name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, shape=(None,10),name=\"Y\")\n",
    "    dropout_op = tf.placeholder(tf.float32)\n",
    "    #froward conv and pool\n",
    "    W1 = tf.get_variable(\"W1\", shape=(5,5,1,32), initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    b1 = tf.get_variable(\"b1\", shape=(32), initializer=tf.constant_initializer(0.))\n",
    "    W2 = tf.get_variable(\"W2\",shape=(5,5,32,64), initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    b2 = tf.get_variable(\"b2\", shape=(64), initializer=tf.constant_initializer(0.))\n",
    "    \n",
    "    conv_1 = tf.nn.conv2d(X, W1, strides=(1,1,1,1), padding=\"SAME\")\n",
    "    conv_1 = tf.nn.relu(conv_1 + b1)\n",
    "    pool_1 = tf.nn.max_pool(conv_1, ksize=(1,2,2,1), strides=(1,2,2,1), padding=\"SAME\")\n",
    "    conv_2 = tf.nn.conv2d(pool_1, W2, strides=(1,1,1,1), padding=\"SAME\")\n",
    "    conv_2 = tf.nn.relu(conv_2+b2)\n",
    "    pool_2 = tf.nn.max_pool(conv_2, ksize=(1,2,2,1), strides=(1,2,2,1), padding=\"SAME\")\n",
    "    #forward fullconnection\n",
    "    pool_2 = tf.contrib.layers.flatten(pool_2)\n",
    "    \n",
    "    W3 = tf.get_variable(\"W3\", shape=(3136, 512), initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    b3 = tf.get_variable(\"b3\", shape=(1, 512), initializer=tf.constant_initializer(0.1))\n",
    "    fc_1 = tf.nn.relu(tf.matmul(pool_2, W3) + b3)\n",
    "    if L2_lambd != 0 :\n",
    "        loss = tf.contrib.layers.l2_regularizer(L2_lambd)(W3)\n",
    "        tf.add_to_collection(\"loss\", loss)\n",
    "    if keep_prob != 0:\n",
    "        fc_1 = tf.nn.dropout(fc_1, dropout_op)\n",
    "    \n",
    "    W4 = tf.get_variable(\"W4\", shape=(512, 10), initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    b4 = tf.get_variable(\"b4\", shape=(1, 10), initializer=tf.constant_initializer(0.1))\n",
    "    Z4 = tf.matmul(fc_1, W4) + b4\n",
    "#     fc_2 = tf.nn.relu(tf.matmul(fc_1, W4) + b4)\n",
    "    if L2_lambd != 0 :\n",
    "        loss = tf.contrib.layers.l2_regularizer(L2_lambd)(W4)\n",
    "        tf.add_to_collection(\"loss\", loss)\n",
    "#     if keep_prob != 0:\n",
    "#         fc_2 = tf.nn.dropout(fc_2, dropout_op)\n",
    "    #compute cost\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z4, labels=Y)) \n",
    "    if L2_lambd != 0:\n",
    "        cost = cost + tf.add_n(tf.get_collection(\"loss\"))\n",
    "    #train\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate_base,\n",
    "                                              global_step,\n",
    "                                              data.shape[0]/batch_size,\n",
    "                                              0.99)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost, global_step = global_step)\n",
    "    #mini-batch\n",
    "    input_queue = tf.train.slice_input_producer([data, labels], shuffle=True)\n",
    "    image_batch, label_batch = tf.train.batch(input_queue, batch_size=batch_size, capacity=64)\n",
    "    #prediction\n",
    "    prediction = tf.cast(tf.argmax(Z4, axis=1), tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y, 1), tf.argmax(Z4, 1)), tf.float32))\n",
    "    \n",
    "    train_cost = []\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        coord=tf.train.Coordinator()\n",
    "        threads= tf.train.start_queue_runners(sess = sess,coord=coord)\n",
    "        seed = 0\n",
    "        for epoch in range(num_epoch):\n",
    "            #mini batch\n",
    "            mini_batch_X, mini_batch_Y = sess.run([image_batch, label_batch])\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: mini_batch_X.reshape(-1,28,28,1), Y: mini_batch_Y, dropout_op:keep_prob})\n",
    "            \n",
    "            if epoch % 10 ==0:\n",
    "                train_cost.append(c/batch_size)\n",
    "            if epoch%1000 == 0:\n",
    "                valid_acc = accuracy.eval({X:mnist_validation_images.reshape(-1,28,28,1), Y:mnist_validation_labels, dropout_op:1.0})\n",
    "                print(\"%d epoch, validation accuracy: %g\" %(epoch, valid_acc))\n",
    "                print(\"%d epoch, train cost: %g\" %(epoch, c/batch_size))\n",
    "                print(\"--------------------------------------------------------\")\n",
    "        y_pred = prediction.eval({X:test.reshape(-1,28,28,1), Y:None, dropout_op:1.0})\n",
    "        df = pd.DataFrame(np.arange(test.shape[0]), columns=['ImageId'])\n",
    "        df['Label'] = y_pred\n",
    "        df.to_csv(\"y_pred.csv\", index=False)\n",
    "#         print(\"%d epoch, test accuracy: %g\"%(epoch, test_acc))\n",
    "        plt.plot(np.squeeze(train_cost))\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_validation_images = mnist_validation.drop(['label'], axis=1).values\n",
    "mnist_validation_labels = pd.get_dummies(mnist_validation['label']).values\n",
    "mnist_train_images = mnist_train.drop(['label'], axis=1).values\n",
    "mnist_train_labels = pd.get_dummies(mnist_train['label']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch, validation accuracy: 0.2195\n",
      "0 epoch, train cost: 7.77077\n",
      "--------------------------------------------------------\n",
      "1000 epoch, validation accuracy: 0.957\n",
      "1000 epoch, train cost: 0.0129033\n",
      "--------------------------------------------------------\n",
      "2000 epoch, validation accuracy: 0.96\n",
      "2000 epoch, train cost: 0.0103999\n",
      "--------------------------------------------------------\n",
      "3000 epoch, validation accuracy: 0.957\n",
      "3000 epoch, train cost: 0.00837443\n",
      "--------------------------------------------------------\n",
      "4000 epoch, validation accuracy: 0.9655\n",
      "4000 epoch, train cost: 0.00701965\n",
      "--------------------------------------------------------\n",
      "5000 epoch, validation accuracy: 0.973\n",
      "5000 epoch, train cost: 0.00600184\n",
      "--------------------------------------------------------\n",
      "6000 epoch, validation accuracy: 0.9565\n",
      "6000 epoch, train cost: 0.00499298\n",
      "--------------------------------------------------------\n",
      "7000 epoch, validation accuracy: 0.971\n",
      "7000 epoch, train cost: 0.00384591\n",
      "--------------------------------------------------------\n",
      "8000 epoch, validation accuracy: 0.973\n",
      "8000 epoch, train cost: 0.0022755\n",
      "--------------------------------------------------------\n",
      "9000 epoch, validation accuracy: 0.9715\n",
      "9000 epoch, train cost: 0.00177496\n",
      "--------------------------------------------------------\n",
      "10000 epoch, validation accuracy: 0.977\n",
      "10000 epoch, train cost: 0.00130173\n",
      "--------------------------------------------------------\n",
      "11000 epoch, validation accuracy: 0.9765\n",
      "11000 epoch, train cost: 0.0008987\n",
      "--------------------------------------------------------\n",
      "12000 epoch, validation accuracy: 0.9825\n",
      "12000 epoch, train cost: 0.000655732\n",
      "--------------------------------------------------------\n",
      "13000 epoch, validation accuracy: 0.9815\n",
      "13000 epoch, train cost: 0.00107626\n",
      "--------------------------------------------------------\n",
      "14000 epoch, validation accuracy: 0.979\n",
      "14000 epoch, train cost: 0.000722715\n",
      "--------------------------------------------------------\n",
      "15000 epoch, validation accuracy: 0.9795\n",
      "15000 epoch, train cost: 0.000966396\n",
      "--------------------------------------------------------\n",
      "16000 epoch, validation accuracy: 0.982\n",
      "16000 epoch, train cost: 0.000451312\n",
      "--------------------------------------------------------\n",
      "17000 epoch, validation accuracy: 0.9845\n",
      "17000 epoch, train cost: 0.000399588\n",
      "--------------------------------------------------------\n",
      "18000 epoch, validation accuracy: 0.9805\n",
      "18000 epoch, train cost: 0.000348669\n",
      "--------------------------------------------------------\n",
      "19000 epoch, validation accuracy: 0.9805\n",
      "19000 epoch, train cost: 0.00239708\n",
      "--------------------------------------------------------\n",
      "20000 epoch, validation accuracy: 0.985\n",
      "20000 epoch, train cost: 0.000316248\n",
      "--------------------------------------------------------\n",
      "21000 epoch, validation accuracy: 0.983\n",
      "21000 epoch, train cost: 0.000242712\n",
      "--------------------------------------------------------\n",
      "22000 epoch, validation accuracy: 0.978\n",
      "22000 epoch, train cost: 0.000330479\n",
      "--------------------------------------------------------\n",
      "23000 epoch, validation accuracy: 0.981\n",
      "23000 epoch, train cost: 0.000230022\n",
      "--------------------------------------------------------\n",
      "24000 epoch, validation accuracy: 0.981\n",
      "24000 epoch, train cost: 0.000264817\n",
      "--------------------------------------------------------\n",
      "25000 epoch, validation accuracy: 0.988\n",
      "25000 epoch, train cost: 0.000180837\n",
      "--------------------------------------------------------\n",
      "26000 epoch, validation accuracy: 0.984\n",
      "26000 epoch, train cost: 0.00018471\n",
      "--------------------------------------------------------\n",
      "27000 epoch, validation accuracy: 0.9855\n",
      "27000 epoch, train cost: 0.000157947\n",
      "--------------------------------------------------------\n",
      "28000 epoch, validation accuracy: 0.9875\n",
      "28000 epoch, train cost: 0.000166019\n",
      "--------------------------------------------------------\n",
      "29000 epoch, validation accuracy: 0.9845\n",
      "29000 epoch, train cost: 0.000152531\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9939c0fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(mnist_train_images, mnist_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8984c19d8015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_cost' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
